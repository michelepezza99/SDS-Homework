---
title: "Homework SDS"
author: "Andrea De Vincenzo, Domenico Azzarito and Michele Pezza"
date: "`r Sys.Date()`"
output:
  html_document:
    css: "styles.css"  # Link to your custom CSS file
fontsize: 12pt
geometry: margin=1in 1in 1in 1in  # Set all margins to 1 inch
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```

# Part 1 
## 1. Bayes classification rule   $\eta^{*}(x)$
$(Y,X)$ are random variables with $Y \in \{0,1\}$ and $X \in \mathbb{R}$.
Suppose that

$$
(X \mid Y = 0) \sim \text{Unif}(-3, 1) \quad \text{and} \quad (X \mid Y = 1) \sim \text{Unif}(-1, 3)
$$

Further suppose that $\mathbb{P}(Y = 0) = \mathbb{P}(Y = 1) = \frac{1}{2}$.

---

The regression function is defined as follows:
$$
r(x) = \mathbb{E}(Y \mid X = x) = \mathbb{P}(Y=1 \mid X = x) = \dfrac{\pi_1f_1(x)}{\pi_1f_1(x) + (1-\pi_1)f_0(x)}
$$

where $\pi_1 = \mathbb{P}(Y = 1), f_1(x) = f(x \mid Y = 1) \text{ and }  f_0(x) = f(x \mid Y = 0)$.


---

The Bayes classification rule $\eta^{*}(x)$ is defined as:

$$
\eta^*(x) = 
\begin{cases} 
1 & \text{if } \mathbb{P}(Y = 1 | X = x) > \mathbb{P}(Y = 0 | X = x) \\
0 & \text{otherwise}
\end{cases} = \begin{cases}
1 & \text{if } \pi_1f_1(x) > (1-\pi_1)f_0(x) \\
0 & \text{otherwise}
\end{cases}
$$



Since we have $\pi_1 = \pi_0 = \frac{1}{2}$:
$$
\eta^*(x) = 
\begin{cases} 
1 & \text{if } f_1(x) > f_0(x) \\
0 & \text{otherwise}
\end{cases}
$$

---

In our setup:
$$
f_1(x) = 
\begin{cases} 
\frac{1}{4} & \text{if } -1 \leq x \leq 3 \\
0 & \text{otherwise}
\end{cases} 
\quad \text{and} \quad f_0(x) = 
\begin{cases} 
\frac{1}{4} & \text{if } -3 \leq x \leq 1 \\
0 & \text{otherwise}
\end{cases} 
$$

---

+ $x < -3$:
$$
f_1(x) = 0, \; f_0(x) = 0 \Rightarrow f_1(x) \not> f_0(x) \Rightarrow \eta^{*}(x) = 0 
$$
+ $-3 \leq x < -1$:
$$
f_1(x) = 0, \; f_0(x) = \frac{1}{4} \Rightarrow f_1(x) \not> f_0(x) \Rightarrow \eta^{*}(x) = 0 
$$
+ $-1 \leq x \leq 1$:
$$
f_1(x) = \frac{1}{4}, \; f_0(x) = \frac{1}{4} \Rightarrow f_1(x) \not> f_0(x) \Rightarrow \eta^{*}(x) = 0 
$$
+ $1 < x \leq 3$:
$$
f_1(x) = \frac{1}{4}, \; f_0(x) = 0 \Rightarrow f_1(x) > f_0(x) \Rightarrow \eta^{*}(x) = 1 
$$
+ $x > 3$:
$$
f_1(x) = 0, \; f_0(x) = 0 \Rightarrow f_1(x) \not> f_0(x) \Rightarrow \eta^{*}(x) = 0
$$


Hence, here the Bayes classification rule $\eta^{*}(x)$ is:


$$
\eta^*(x) = 
\begin{cases} 
1 & \text{if} \quad 1 < x \leq 3 \\
0 & \text{otherwise}
\end{cases}
$$

## 2.1 
Now, we generate a dataset of size $n = 1000$ from the joint data model $p(y, x) = p(x | y) \cdot p(y)$ described earlier. 
The data will include samples drawn from the specified uniform distributions for $X$ conditioned on $Y$. 
We will then visualize the generated dataset.

```{r point 1.2, echo=TRUE}
source('Functions.R')
set.seed(54) # We begin with setting the seed for reproducibility
n <- 1000 # Sample size 
# Define the distribution

# We simulate one dataset
data <- simulate(n)  # defined in 'Functions.R'

# Plot the data
plot(data$x, data$y, 
     col = ifelse(data$y == 1, adjustcolor("darkred", alpha.f = 0.1), 
                                  adjustcolor("darkblue", alpha.f = 0.1)), 
     pch = 16, cex = 0.7, xlab = "X", ylab = "Y", 
     main = "Generated dataset and Regression function", 
     sub = expression(eta(x) == 1 ~ "if and only if" ~ r(x) > 0.5))

# Plot the Regression Function r(x)
x_seq <- seq(-3, 3, length.out = 1000)
r_values <- reg_fun(x_seq)   # 

lines(x_seq, r_values, type = 's', 
      col = adjustcolor("darkgreen", alpha.f = 0.4), 
      lwd = 3) 

# Add the regression function threshold
abline(h = 0.5, lty = 3, lwd =2)

# Add Legend
legend("topleft", legend = c("Y = 0", "Y = 1", "r(x)",'threshold'), 
       col = c('darkblue','darkred','darkgreen','black'), lty = c(0, 0, 1,3), 
       pch = c(16, 16, NA,NA), pt.cex = c(0.7, 0.7, NA,NA), lwd = c(NA, NA, 2,2))
```


This visualization shows the generated dataset and the regression function $r(x)$ used to model the probability of $Y = 1$. The blue points represent observations where the outcome is 0, and the red points represent observations where the outcome is 1. The green stepwise line represents the regression function $r(x)$, which models the posterior probability $\mathbb{P}(Y = 1 | X = x)$ based on the underlying distributions defined for $X$ given $Y$. The stepwise nature of the function reflects how probabilities change sharply at the boundaries, consistent with the uniform distributions specified in the data generation process. The dotted black horizontal line at $r(x) = 0.5$ acts as a classification threshold. According to the Bayes classifier, $\eta(x) = 1$ if and only if $r(x) > 0.5$. This decision rule splits the feature space into two regions: predicted as $Y = 0$ where $r(x) \leq 0.5$ and predicted as $Y = 1$ where $r(x) > 0.5$. 

## 2.2

Now, we focus on the evaluation of the Bayes classifier.
```{r point 1.3, echo=TRUE}
# We evaluate its performance

# Predict using the Bayes classifier
data$y_pred <- bayes_classifier(data$x)

accuracy <- mean(data$y == data$y_pred) * 100
cat("Accuracy of Bayes Classifier: ", accuracy, "%\n",sep = '')

```

```{r, echo=TRUE}
cat("Size of Y = 0: ", sum(data$y == 0), "\n")
cat("Size of Y = 1: ", sum(data$y == 1), "\n")

```

Since the dataset is balanced, Accuracy alone is a reliable metric for evaluating the performance of the classifier.

## 2.3
Here, we consider a comparison between the Bayes classifier and the Logistic regression classifier.

Logistic regression is a supervised machine learning algorithm used for binary classification problems. It models the probability that an observation belongs to the positive class, $Y = 1$, given input features, $X_1, \ldots, X_p$. The probability is modeled using the logistic (sigmoid) function:

$$
\mathbb{P}(Y = 1 | X) = \frac{1}{1 + e^{-z}}
$$

where $z = \beta_0 + \beta_1 X_1 + \beta_2 X_2 + \dots + \beta_p X_p$ is a linear combination of input features, and $\beta$ are parameters estimated using Maximum Likelihood Estimation (MLE). Predictions are made by assigning $Y = 1$ if $\mathbb{P}(Y = 1 | X) > 0.5$ and $Y = 0$ otherwise. Logistic regression assumes a linear relationship between the features and the log-odds, independent observations, and no multicollinearity. 

To implement our logistic regression model, we use $k$-fold cross-validation to evaluate its performance. Specifically, we partition the simulated dataset into $k = 5$ folds, ensuring that each observation is used for both training and validation at least once. In each iteration, one fold serves as the validation set, while the remaining $k-1$ folds are combined to form the training set.

The logistic regression model is trained on the training set, and predictions are made on the validation set. The model's accuracy is calculated for each fold, and the process is repeated for all $k$ folds. Finally, the cross-validated accuracy is obtained by averaging the accuracies across all folds, providing a robust estimate of the model's performance.

By using $k$-fold cross-validation, we ensure a more reliable evaluation compared to a single train-test split, as all data points contribute to both training and validation, mitigating potential biases due to random partitioning.


```{r}
set.seed(54)

# Perform 5-fold cross-validation using the defined function
mean_accuracy <- cross_validate(data, k = 5)

# Print the result
cat("Mean Cross-Validated Accuracy: ", mean_accuracy, "%\n")




```

The two accuracies—76% for the Bayes classifier and 74.5% for the logistic regression model evaluated using 5-fold cross-validation—reflect the performance differences between the theoretical and practical classifiers.

The Bayes classifier achieves a slightly higher accuracy as it directly leverages the known underlying data-generating process, making it the optimal theoretical benchmark for classification in this setup. In contrast, logistic regression relies on learning the decision boundary from the data, which introduces slight variability and a minor performance drop due to the practical challenges of model estimation and potential misalignment with the true data distribution.

The difference is small, suggesting that logistic regression performs reasonably well, even though it does not have access to the exact data-generating process. This highlights logistic regression's robustness and adaptability as a practical classifier in real-world scenarios.


## 3. Repeated Sampling

In this section, we perform a repeated sampling experiment to compare the performance of the Bayes classifier and logistic regression. Specifically, we simulate $M = 10,000$ datasets, each with $n = 1,000$ observations, drawn from the specified data-generating process. 

For each simulated dataset:
1. The Bayes classifier is applied to the entire dataset, and its accuracy is recorded. This serves as the theoretical benchmark since it directly leverages the known underlying distributions.
2. Logistic regression is evaluated using 5-fold cross-validation on the same dataset. The cross-validated accuracy is recorded to represent the practical performance of a data-driven classifier.

After $M$ repetitions, we calculate the mean and standard deviation of accuracies for both classifiers. This repeated sampling approach provides insights into the average performance and variability of the classifiers, enabling a robust comparison under simulated conditions.


```{r, echo=TRUE}
set.seed(54)
M <- 10000  # Number of repetitions
n <- 1000   # Sample size

# Initialize vectors to store accuracies
accuracy_bayes <- numeric(M)
accuracy_logistic <- numeric(M)

# Loop for repeated sampling
for (i in 1:M) {
  # Generate new dataset
  data <- simulate(n)
  
  # Bayes Classifier: Evaluate on all data
  data$y_pred <- bayes_classifier(data$x)
  accuracy_bayes[i] <- mean(data$y == data$y_pred)
  
  # Logistic Regression: Use cross-validation
  accuracy_logistic[i] <- cross_validate(data, k = 5)
}

# Compute summary statistics
mean_bayes <- mean(accuracy_bayes) * 100
mean_logistic <- mean(accuracy_logistic) 
sd_bayes <- sd(accuracy_bayes) * 100
sd_logistic <- sd(accuracy_logistic) 

cat("Bayes Classifier - Mean Accuracy: ", mean_bayes, "%, Std Dev: ", sd_bayes, "%\n")
cat("Logistic Regression - Mean Accuracy: ", mean_logistic, "%, Std Dev: ", sd_logistic, "%\n")



```

The results of the repeated sampling experiment show that logistic regression slightly outperforms the Bayes classifier. The **Bayes classifier** achieves a mean accuracy of approximately 74.98% with a standard deviation of 1.38%, while **logistic regression**, evaluated using 5-fold cross-validation, attains a slightly higher mean accuracy of 75.02% with a lower standard deviation of 1.37%.

The slight edge in performance for logistic regression may seem counterintuitive, as the Bayes classifier is theoretically optimal under the assumption that the data-generating process is perfectly known. However, this outcome highlights an important distinction: while the Bayes classifier relies entirely on the assumed uniform distributions for $X \mid Y$, logistic regression leverages the data itself to learn the decision boundary. This data-driven approach allows logistic regression to adapt to small deviations or noise in the simulated data that might not perfectly align with the assumed theoretical distributions.

Moreover, the cross-validation process used for logistic regression helps mitigate overfitting by effectively utilizing the dataset to generalize better across folds. This adaptability gives logistic regression a practical advantage in real-world scenarios where the true underlying distribution is unknown or subject to variability.

Overall, these results underscore the power of logistic regression as a flexible and robust classifier, capable of achieving performance comparable to or even surpassing theoretical benchmarks like the Bayes classifier in applied settings.


```{r}

```


